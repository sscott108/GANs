{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from mtl_utils import *\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the size of the image requries changing script code for the discriminator in the linear output line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Temp_Dataset('/datacommons/carlsonlab/srs108/old/ol/Mumbai.pkl', transform=True) #source\n",
    "x2 = Temp_Dataset('/datacommons/carlsonlab/srs108/old/ol/Shanghai.pkl', transform = True) #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = DataLoader(x1, batch_size=4)\n",
    "target = DataLoader(x2, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken directly from cycleGAN Github page.\n",
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        \"\"\"Construct a Resnet-based generator\n",
    "        Parameters:\n",
    "            input_nc (int)      -- the number of channels in input images\n",
    "            output_nc (int)     -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Initialize the Resnet block\n",
    "        A resnet block is a conv block with skip connections\n",
    "        We construct a conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> function.\n",
    "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Construct a convolutional block.\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
    "        \"\"\"\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'padding_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4a0dccd8d9ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnorm_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnetGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-65e72842012e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_nc, output_nc, ngf, norm_layer, use_dropout, n_blocks, padding_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;31m# add ResNet blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mResnetBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_downsampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# add upsampling layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'padding_type'"
     ]
    }
   ],
   "source": [
    "norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "net = ResnetGenerator(3, 3, 64, norm_layer=norm_layer, use_dropout=False, n_blocks=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initializing networks\n",
    "lr = 0.00002\n",
    "Gen_S_T = Generator(input_dim=3, num_filter=64, num_res=6)\n",
    "Gen_T_S = Generator(input_dim=3, num_filter = 64, num_res=6)\n",
    "\n",
    "Dis_T = Discriminator(input_dim = 3, num_filter=64)\n",
    "Dis_S = Discriminator(input_dim=3, num_filter=64)\n",
    "\n",
    "Dis_Feat = Discriminator_Task(input_dim=1, hidden_dim= 500)\n",
    "\n",
    "regressor_S = Regressor_Task()\n",
    "regressor_T = Regressor_Task()\n",
    "\n",
    "#Initializing weights\n",
    "Gen_S_T.apply(weights_init_normal)\n",
    "Gen_T_S.apply(weights_init_normal)\n",
    "Dis_T.apply(weights_init_normal)\n",
    "Dis_S.apply(weights_init_normal)\n",
    "Dis_Feat.apply(weights_init_normal)\n",
    "print()\n",
    "\n",
    "#move to GPU\n",
    "Gen_S_T.cuda()\n",
    "Gen_T_S.cuda()\n",
    "Dis_T.cuda()\n",
    "Dis_S.cuda()\n",
    "Dis_Feat.cuda()\n",
    "regressor_S.cuda()\n",
    "regressor_T.cuda()\n",
    "print()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(Gen_S_T.parameters(), Gen_T_S.parameters()), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(itertools.chain(Dis_T.parameters(), Dis_S.parameters()), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "optimizer_D_feat = torch.optim.Adam(Dis_Feat.parameters(), lr= lr/10, betas = (0.5,0.999))\n",
    "\n",
    "optimizer_R_S = torch.optim.Adam(regressor_S.parameters(), lr=lr, betas = (0.5, 0.999))\n",
    "optimizer_R_T = torch.optim.Adam(regressor_T.parameters(), lr=lr, betas = (0.5, 0.999))\n",
    "\n",
    "#Losses\n",
    "f_loss = torch.nn.MSELoss() #.cuda() ?\n",
    "cycle_loss = torch.nn.L1Loss() #.cuda()?\n",
    "gan_loss = GANLoss().cuda()\n",
    "feat_loss = torch.nn.modules.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'generator_S_T': Gen_S_T,\n",
    "    'generator_T_S': Gen_T_S,\n",
    "    'discriminator_S': Dis_S,\n",
    "    'discriminator_T': Dis_T,\n",
    "    'feature_dis': Dis_Feat,\n",
    "    'regressor_S': regressor_S,\n",
    "    'regressor_T': regressor_T,\n",
    "    'optimizer_G': optimizer_G,\n",
    "    'optimizer_D': optimizer_D,\n",
    "    'optimizer_D_feat': optimizer_D_feat,\n",
    "    'optimizer_R_S': optimizer_R_S,\n",
    "    'optimizer_R_T': optimizer_R_T\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFunction():\n",
    "                                \n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        for net in nets:\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    def class_prediction(self, out, target=None):\n",
    "        out=out.detach().cuda()\n",
    "        target=target.cuda()\n",
    "        label = torch.where(out > 0.5, torch.ones_like(out).cuda(), torch.zeros_like(out).cuda())\n",
    "        acc = (out.data == target).sum().item() / target.size()[0]\n",
    "        return label, acc\n",
    "    \n",
    "    def visualize(self, source, target, fake_source, fake_target):\n",
    "        fig, ax = plt.subplots(2,2, figsize=(8,8))\n",
    "        source = source.T\n",
    "        target = target.T\n",
    "        fake_source= fake_source.T\n",
    "        fake_target = fake_target.T\n",
    "        \n",
    "#         print(fake_source)\n",
    "#         print(source.shape, target.shape, fake_source.shape,fake_target.shape)\n",
    "        ax[0,0].imshow(source)\n",
    "        \n",
    "        ax[0,1].imshow(target)\n",
    "        \n",
    "        ax[1,0].imshow(fake_source)\n",
    "        \n",
    "        ax[1,1].imshow(fake_target)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minimax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyCADA(nn.Module, BaseFunction):\n",
    "    def __init__(self, config):\n",
    "        super(CyCADA, self).__init__()\n",
    "\n",
    "        self.gen_s_t = config['generator_S_T']\n",
    "        self.gen_t_s = config['generator_T_S']\n",
    "        self.dis_s = config['discriminator_S']\n",
    "        self.dis_t = config['discriminator_T']\n",
    "        self.feat_dis = config['feature_dis']\n",
    "        self.regressor_s = config['regressor_S']\n",
    "        self.regressor_t = config['regressor_T']\n",
    "        self.optimizer_G = config['optimizer_G']\n",
    "        self.optimizer_D = config['optimizer_D']\n",
    "        self.optimizer_D_feat = config['optimizer_D_feat']\n",
    "        self.optimizer_R_S = config['optimizer_R_S']\n",
    "        self.optimizer_R_T = config['optimizer_R_T']\n",
    "        \n",
    "        self.ganloss = GANLoss() #.cuda()\n",
    "        self.mseloss = torch.nn.MSELoss()\n",
    "        self.cycleloss = torch.nn.L1Loss()\n",
    "        self.featloss = torch.nn.modules.BCEWithLogitsLoss()\n",
    "#________________________________________________________________________________________________________________        \n",
    "    def forward(self,source_image, target_image, s_label):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        \n",
    "        self.source_image = source_image\n",
    "        self.target_image = target_image\n",
    "        self.label = s_label\n",
    "\n",
    "        self.source_label = torch.ones(self.source_image.size()[0]).long().cuda() #source domain\n",
    "        self.target_label = torch.zeros(self.target_image.size()[0]).long().cuda()#target domain\n",
    "        \n",
    "        #S-->T\n",
    "        self.fake_target_img = self.gen_s_t(self.source_image) #gen(s)\n",
    "        self.reconstructed_source = self.gen_t_s(self.fake_target_img)\n",
    "        \n",
    "        #T-->S\n",
    "        self.fake_source_img = self.gen_t_s(self.target_image)\n",
    "        self.reconstructed_target = self.gen_s_t(self.fake_source_img)\n",
    "        \n",
    "\n",
    "        ##using generated images in D_ft\n",
    "        pred_source = self.feat_dis(self.regressor_t(self.fake_target_img.detach())) # D_ft(C_A(G_A(A)))\n",
    "        pred_target = self.feat_dis(self.regressor_t(self.target_image))             # D_ft(C_B(B))\n",
    "        \n",
    "        _, self.acc_d_ft_source = self.class_prediction(pred_source.squeeze(), self.source_label)\n",
    "        _, self.acc_d_ft_target = self.class_prediction(pred_target.squeeze(), self.target_label)\n",
    "        self.score_acc_D_ft = (self.acc_d_ft_source + self.acc_d_ft_target)/2 #feature discriminator accuracy\n",
    "        \n",
    "        \n",
    "    def backward_regressor_s(self):\n",
    "        f_s_source = self.mseloss(self.regressor_s(self.source_image),self.regressor_s(self.fake_target_img)) \n",
    "        f_s_targ = self.mseloss(self.regressor_s(self.target_image), self.regressor_s(self.fake_source_img))\n",
    "        self.f_s_loss = f_s_source + f_s_targ\n",
    "        self.f_s_loss.backward()\n",
    "    \n",
    "    def backward_gen(self):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        self.cycle_recon_loss_source = self.cycleloss(self.reconstructed_source.detach(), self.source_image)\n",
    "        self.cycle_recon_loss_target = self.cycleloss(self.reconstructed_target.detach(), self.target_image)\n",
    "        \n",
    "        self.gan_loss_S_T = self.ganloss(self.dis_s(self.gen_s_t(self.source_image)), True) #*\n",
    "        self.gan_loss_T_S = self.ganloss(self.dis_t(self.gen_t_s(self.target_image)), True)\n",
    "        \n",
    "        self.rloss_s = self.mseloss(self.regressor_s(self.source_image), self.regressor_s(self.fake_target_img.detach()))\n",
    "        self.rloss_t = self.mseloss(self.regressor_t(self.target_image), self.regressor_t(self.fake_source_img.detach()))\n",
    "        \n",
    "        self.total_gen = self.rloss_s + self.rloss_t + self.cycle_recon_loss_source + self.cycle_recon_loss_target + self.gan_loss_S_T + self.gan_loss_T_S \n",
    "        self.total_gen.backward()\n",
    "\n",
    "    def backward_dis(self, netD, real, fake):\n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.ganloss(pred_real, True)\n",
    "\n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.ganloss(pred_fake, False)\n",
    "\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        true_labels = torch.ones(real.size()[0]).long()\n",
    "        fake_labels = torch.zeros(fake.detach().size()[0]).long()\n",
    "        \n",
    "        _, true_acc = self.class_prediction(pred_real.squeeze().cpu(), true_labels)\n",
    "        _, fake_acc = self.class_prediction(pred_fake.squeeze().cpu(), fake_labels)\n",
    "        acc = (true_acc + fake_acc) * 0.5\n",
    "        return loss_D ,acc\n",
    "    \n",
    "    def backward_D_S(self):\n",
    "        self.loss_D_S_from_T, self.score_acc_d_S  = self.backward_dis(self.dis_s, self.target_image, self.fake_target_img)\n",
    "        self.loss_D_S_from_T.backward()\n",
    "\n",
    "    def backward_D_T(self):\n",
    "        self.loss_D_T_from_S, self.score_acc_d_T = self.backward_dis(self.dis_t, self.source_image, self.fake_source_img)\n",
    "        self.loss_D_T_from_S.backward()\n",
    "        \n",
    "    def backward_regressor_T(self):\n",
    "        pred_target = self.regressor_t(self.fake_target_img.detach()) #purple\n",
    "        self.loss_reg_mse = self.mseloss(pred_target, self.label)     #purple\n",
    "        \n",
    "        if self.score_acc_D_ft > 0.1: \n",
    "            pred_target = self.feat_dis(self.regressor_t(self.target_image))\n",
    "            target_label = torch.ones(self.target_image.size()[0]).cuda()\n",
    "#             print(pred_target.shape, target_label.shape)\n",
    "            self.loss_ft_D_targ = self.featloss(pred_target.squeeze(dim=1), target_label)\n",
    "        else:\n",
    "            self.loss_ft_D_targ = 0\n",
    "        self.loss_reg_t = self.loss_reg_mse + self.loss_ft_D_targ\n",
    "        self.loss_reg_t.backward()\n",
    "    \n",
    "            \n",
    "    def backward_D_feat(self):\n",
    "        # Source\n",
    "        pred_source = self.feat_dis(self.regressor_t(self.fake_target_img.detach())) #d_feat class predictions\n",
    "\n",
    "        loss_D_ft_s = self.featloss(pred_source.squeeze(dim=1), self.source_label.float())\n",
    "        # Target\n",
    "        pred_target = self.feat_dis(self.regressor_t(self.target_image))\n",
    "        loss_D_ft_t = self.featloss(pred_target.squeeze(dim=1), self.target_label.float())\n",
    "        # Combined loss\n",
    "        self.loss_D_ft_adv = (loss_D_ft_s + loss_D_ft_t) * 0.5\n",
    "        self.loss_D_ft_adv.backward()\n",
    "        \n",
    "    def runthrough(self, source_image, target_image, s_label):\n",
    "        \n",
    "        self.forward(source_image, target_image, s_label)\n",
    "        \n",
    "        self.set_requires_grad([self.regressor_s], True) #training source regressor\n",
    "        self.optimizer_R_S.zero_grad()\n",
    "        self.backward_regressor_s()\n",
    "        self.optimizer_R_S.step()\n",
    "        \n",
    "\n",
    "#         generators\n",
    "        self.set_requires_grad([self.dis_s, self.dis_t, self.regressor_s], False)\n",
    "        self.set_requires_grad([self.gen_s_t, self.gen_t_s], True)\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.optimizer_R_S.zero_grad()\n",
    "        self.backward_gen()\n",
    "        self.optimizer_G.step()\n",
    "        \n",
    "        self.visualize(self.source_image[0].cpu().numpy(), \n",
    "               self.target_image[0].cpu().numpy(), \n",
    "               self.fake_source_img[0].detach().cpu().numpy(),\n",
    "               self.fake_target_img[0].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "#         discriminators\n",
    "        self.set_requires_grad([self.dis_s, self.dis_t], True)\n",
    "        self.optimizer_D.zero_grad()\n",
    "        self.backward_D_S()\n",
    "        self.backward_D_T()\n",
    "        self.optimizer_D.step()\n",
    "        \n",
    "        self.set_requires_grad([self.feat_dis], False)\n",
    "        self.set_requires_grad([self.regressor_t], True)\n",
    "        self.optimizer_R_T.zero_grad()\n",
    "        self.backward_regressor_T()\n",
    "        self.optimizer_R_T.step()\n",
    "        \n",
    "#           D_ft\n",
    "        self.set_requires_grad([self.regressor_t], False)\n",
    "        self.set_requires_grad([self.feat_dis], True)\n",
    "        self.optimizer_D_feat.zero_grad()\n",
    "        self.backward_D_feat()\n",
    "        self.optimizer_D_feat.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CyCADA(config).to(device)\n",
    "\n",
    "for i, (s, t) in enumerate(zip(source, target)):\n",
    "    \n",
    "    source_image = s['img'].to(device).float()\n",
    "    target_image = t['img'].to(device).float()\n",
    "    source_label = s['lbl'].to(device).float()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    model.runthrough(source_image, target_image, source_label)\n",
    "\n",
    "    i+=1\n",
    "    print(f'run:{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
