{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b88af3678f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcycada_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepoch\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_epochs\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_work/cycle_stuff/cycle_gan/cycada_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# In[2]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from . import (  # usort:skip. Keep the order instead of sorting lexicographically\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/onnx/symbolic_caffe2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbolic_helper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_opset9\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopset9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/onnx/symbolic_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Monkey-patch graph manipulation methods on Graph, used for the ONNX symbolics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from torch.onnx import (  # noqa: F401\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/onnx/_patch_torch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Import utils to get _params_dict because it is a global that is accessed by c++ code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_globals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLOBALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_beartype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onnx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0;31m from torch.jit._trace import (\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrace_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_isfile\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_is_mode_type\u001b[0;34m(path, mode)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cycada_utils import *\n",
    "\n",
    "epoch        = 0 \n",
    "n_epochs     = 100\n",
    "batch_size   = 1\n",
    "lr           = 0.0002\n",
    "b1           = 0.5 \n",
    "b2           = 0.999 \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'On {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(dataloader, e, i):\n",
    "    \"\"\"show a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(dataloader))\n",
    "    G_AB.eval()\n",
    "    G_BA.eval()\n",
    "    real_A = imgs['A'].type(Tensor) # A : monet\n",
    "    fake_B = G_AB(real_A).detach()\n",
    "    real_B = imgs['B'].type(Tensor) # B : photo\n",
    "    fake_A = G_BA(real_B).detach()\n",
    "    recona = G_BA(fake_B).detach()\n",
    "    reconb = G_AB(fake_A).detach() \n",
    "\n",
    "    # Resize images to 10 by 10\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "    real_B = make_grid(real_B, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "    fake_A = make_grid(fake_A, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "    reconA = make_grid(recona, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "    reconB = make_grid(reconb, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "\n",
    "    # Arange images along y-axis    \n",
    "    image_grid = torch.cat((real_A, fake_B, real_B, fake_A, reconA, reconB), 1)\n",
    "    plt.imshow(image_grid.cpu().permute(1,2,0))\n",
    "    plt.title('Real A vs Fake B | Real B vs Fake A| Recon A vs Recon B')\n",
    "    plt.axis('off')\n",
    "    plt.gcf().set_size_inches(10, 10) # set image size to 10 by 10 inches\n",
    "    plt.savefig(os.path.join('Figure_PDFs', f'epoch_{str(e)}_iter{str(i)}.png' ))\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/datacommons/carlsonlab/srs108/planet_imgs'\n",
    "files_train = sorted(glob.glob(os.path.join(root+'/usembassy')+'/*.*')[:])\n",
    "paired_files_train = [(img, 1) for img in files_train]\n",
    "random.shuffle(paired_files_train)\n",
    "\n",
    "files_test = sorted(glob.glob(os.path.join(root+'/thil')+'/*.*')[:])\n",
    "paired_files_test = [(img, 0) for img in files_test]\n",
    "random.shuffle(paired_files_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-1dd1ee9cd19a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-1dd1ee9cd19a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    len(paired_f iles_train)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "len(paired_f iles_train)\n",
    "len(files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-600b78352682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaired_files_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaired_files_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "image_path = paired_files_train[index][0]\n",
    "label_tr = self.paired_files_train[index][1]\n",
    "image_tr = Image.open(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.mode = mode\n",
    "\n",
    "        self.files_train = sorted(glob.glob(os.path.join(root+'/usembassy')+'/*.*')[:])\n",
    "        self.paired_files_train = [(img, 1) for img in self.files_train]\n",
    "        random.shuffle(self.paired_files_train)\n",
    "        \n",
    "        self.files_test = sorted(glob.glob(os.path.join(root+'/thil')+'/*.*')[:])\n",
    "        self.paired_files_test = [(img, 0) for img in self.files_test]\n",
    "        random.shuffle(self.paired_files_test)\n",
    "\n",
    "    def  __getitem__(self, index):\n",
    "        \n",
    "        image_path = self.paired_files_train[index][0]\n",
    "        label_tr = self.paired_files_train[index][1]\n",
    "        image_tr = Image.open(image_path)\n",
    "\n",
    "\n",
    "        item_te = self.transform(image_te)\n",
    "        label_te = self.paired_files_test[index][1]\n",
    "            \n",
    "        return {'img_tr':item_tr, \n",
    "                'lbl_tr': label_tr,\n",
    "                'img_te':item_te,\n",
    "                'lbl_te':label_te}\n",
    "    \n",
    "    def __len__(self): return len(self.paired_files_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CyDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3bcbcba2829d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/datacommons/carlsonlab/srs108/planet_imgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munaligned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m dataloader = DataLoader(\n\u001b[1;32m      3\u001b[0m     \u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     shuffle=True,)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CyDataset' is not defined"
     ]
    }
   ],
   "source": [
    "tr = CyDataset(root='/datacommons/carlsonlab/srs108/planet_imgs', transforms_=transforms_, unaligned=True)\n",
    "dataloader = DataLoader(\n",
    "    tr,\n",
    "    batch_size=1, # 1\n",
    "    shuffle=True,)\n",
    "val_dataloader = DataLoader(\n",
    "    tr,\n",
    "    batch_size=5,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_acc(prediction, target_is_real=True):\n",
    "    pred_labels = torch.round(torch.sigmoid(prediction)).squeeze()\n",
    "    true_labels = torch.ones_like(pred_labels) if target_is_real else torch.zeros_like(pred_labels)\n",
    "\n",
    "    correct_predictions = torch.sum(pred_labels == true_labels).item()\n",
    "    total_predictions = true_labels.size(0) \n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "G_AB = ResnetGenerator(3, 3, 64, norm_layer=norm_layer, use_dropout=False, n_blocks=9)\n",
    "G_BA = ResnetGenerator(3,3,64, norm_layer=norm_layer, use_dropout=False, n_blocks=9)\n",
    "\n",
    "D_A = NLayerDiscriminator(3)\n",
    "D_B = NLayerDiscriminator(3)\n",
    "D_ft = FeatureDiscriminator()\n",
    "\n",
    "C_A = Feature_Extractor()\n",
    "C_B = LeNet(3)\n",
    "\n",
    "G_AB.to(device)\n",
    "G_BA.to(device)\n",
    "D_A.to(device)\n",
    "D_B.to(device)\n",
    "D_ft.to(device)\n",
    "C_A.to(device)\n",
    "C_B.to(device)\n",
    "\n",
    "ganloss = GANLoss().to(device)                         #use to fool discriminator\n",
    "cycleloss = torch.nn.L1Loss().to(device)               #difference between reconstructed img and original\n",
    "identityloss = torch.nn.L1Loss().to(device)            #difference between generator output from input img and input img\n",
    "clsloss = torch.nn.CrossEntropyLoss().to(device)       #difference between domain classifications between input img and generator output\n",
    "\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1,b2))\n",
    "optimizer_D = torch.optim.Adam(itertools.chain(D_A.parameters(), D_B.parameters()), lr=lr, betas=(b1, b2))\n",
    "optimizer_C_A = torch.optim.Adam(C_A.parameters(), lr=lr, betas=(b1, 0.999))    \n",
    "optimizer_C_B = torch.optim.Adam(C_B.parameters(), lr=lr, betas=(b1, 0.999))    #different learning rate??\n",
    "optimizer_D_ft = torch.optim.Adam(D_ft.parameters(), lr=lr/10, betas=(b1, 0.999))\n",
    "\n",
    "\n",
    "G_AB.apply(weights_init_normal)\n",
    "G_BA.apply(weights_init_normal)\n",
    "D_A.apply(weights_init_normal)\n",
    "D_B.apply(weights_init_normal)\n",
    "D_ft.apply(weights_init_normal)\n",
    "C_A.apply(weights_init_normal)\n",
    "C_B.apply(weights_init_normal)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3ec48ece4fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_tr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_te'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "Tensor      = torch.cuda.FloatTensor\n",
    "G_loss      = []\n",
    "D_loss      = []\n",
    "D_accs      = []\n",
    "Dft_loss    = []\n",
    "num_classes = 2\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        real_A = batch['img_tr'].type(Tensor)\n",
    "        real_B = batch['img_te'].type(Tensor)\n",
    "        real_lbl = batch['lbl_tr'].type(Tensor).long()\n",
    "        \n",
    "        oneh = torch.eye(num_classes).to(device)\n",
    "        \n",
    "        source_label = torch.ones(real_A.size()[0]).long().to(device)\n",
    "        target_label = torch.zeros(real_B.size()[0]).long().to(device)\n",
    "        \n",
    "        G_AB.train()\n",
    "        G_BA.train()\n",
    "        \n",
    "        \n",
    "          \n",
    "        #Generator Forward Pass\n",
    "        fake_b         = G_AB(real_A)             #used throughout\n",
    "        fake_a         = G_BA(real_B)             #used only for cycle loss and discriminator A\n",
    "        recov_a        = G_BA(fake_b)\n",
    "        recov_b        = G_AB(fake_a)\n",
    "# ---------------------------------------------------------------------------------\n",
    "        #Feature Discriminator Forward Pass\n",
    "        pred_source    = D_ft(C_B(fake_b.detach())) # D_ft(C_B(G_A(A)))\n",
    "        pred_target    = D_ft(C_B(real_B))          # D_ft(C_B(B))\n",
    "        \n",
    "        dft_acc_source = discriminator_acc(pred_source, True)\n",
    "        dft_acc_targ   = discriminator_acc(pred_target, False)\n",
    "        \n",
    "        acc_D_ft       = (dft_acc_source + dft_acc_targ)/2 #feature discriminator accuracy\n",
    "        \n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_GAN_AB, _ = ganloss(D_B(fake_b), True)                # tricking the 'fake-B' into 'real-B'\n",
    "        loss_GAN_BA, _ = ganloss(D_A(fake_a), True)                # tricking the 'fake-A' into 'real-A'\n",
    "        loss_GAN       = (loss_GAN_AB + loss_GAN_BA)/2\n",
    "        \n",
    "        # cycle loss                                \n",
    "        loss_cycle_A   = cycleloss(recov_a, real_A)               # Reduces the difference between the restored image and the real image\n",
    "        loss_cycle_B   = cycleloss(recov_b, real_B)\n",
    "        loss_cycle     = (loss_cycle_A + loss_cycle_B)/2\n",
    "        \n",
    "        loss_G         = loss_GAN + (10.0*loss_cycle) # multiply suggested weight(default cycle loss weight : 10, default identity loss weight : 5)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        G_loss.append(loss_G.item())\n",
    "        \n",
    "# ----------------------------\n",
    "# Train Feature Discriminator\n",
    "# ----------------------------\n",
    "        optimizer_D_ft.zero_grad()\n",
    "        D_ft.train()\n",
    "        \n",
    "        loss_real_dft, _ = ganloss(D_ft(C_B(real_B)), True)                 \n",
    "        loss_fake_dft, _ = ganloss(D_ft(C_B(fake_b.detach())), False)\n",
    "                \n",
    "        dft_loss = (loss_real_dft + loss_fake_dft)*0.5\n",
    "        dft_loss.backward()\n",
    "        optimizer_D_ft.step()\n",
    "        Dft_loss.append(dft_loss.item())\n",
    "        \n",
    "# -----------------------------------------\n",
    "# Train Discriminator A and Discriminator B\n",
    "# -----------------------------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        loss_real_a, _ = ganloss(D_A(real_A), True)                # train to discriminate real images as real\n",
    "        loss_fake_a, _ = ganloss(D_A(fake_a.detach()), False)      # train to discriminate fake images as fake\n",
    "        \n",
    "        loss_D_A       = (loss_real_a + loss_fake_a)/2\n",
    "    \n",
    "        loss_real_b, _ = ganloss(D_B(real_B), True)                 # train to discriminate real images as real\n",
    "        loss_fake_b, _ = ganloss(D_B(fake_b.detach()), False)       # train to discriminate fake images as fake\n",
    "        \n",
    "        loss_D_B       = (loss_real_b + loss_fake_b)/2\n",
    "        \n",
    "        loss_D_A.backward()\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        loss_D         = (loss_D_A + loss_D_B)/2\n",
    "    \n",
    "        D_loss.append(loss_D.item())\n",
    "        \n",
    "# -----------------\n",
    "# Train Classifier A  #remember you only call this on training domain bc we only have labels for that domain.\n",
    "# -----------------\n",
    "        optimizer_C_A.zero_grad()\n",
    "        real_c        = C_A(real_A)\n",
    "        fake_c        = C_A(fake_b.detach())\n",
    "        sem_loss_a    = clsloss(real_c, oneh[real_lbl])                    #cross entropy loss\n",
    "        sem_loss_aa   = clsloss(fake_c, oneh[real_lbl])\n",
    "        sem_loss      = (sem_loss_a + sem_loss_aa)/2\n",
    "        \n",
    "        sem_loss.backward()\n",
    "        optimizer_C_A.step()\n",
    "        \n",
    "# -------------------\n",
    "# Train Classifier B\n",
    "# -------------------\n",
    "\n",
    "        optimizer_C_B.zero_grad()\n",
    "        cb_fake       = C_B(fake_b.detach()) \n",
    "        cb_loss       = clsloss(cb_fake, oneh[real_lbl]) #purple part in paper?\n",
    "\n",
    "        if acc_D_ft   > 0.6:\n",
    "            cb_real   = D_ft(C_B(real_B))\n",
    "            tgt_lbl   = torch.ones(real_B.size()[0]).long().to(device)\n",
    "            losscbadv = clsloss(cb_real, tgt_lbl)\n",
    "        else:\n",
    "            losscbadv = 0\n",
    "        loss_C_B      = cb_loss + losscbadv\n",
    "        \n",
    "        loss_C_B.backward()\n",
    "        optimizer_C_B.step()\n",
    "\n",
    "\n",
    "        \n",
    "# ---------------------------------Visualization---------------------------------       \n",
    "#         if (i+1) % 200 == 0:\n",
    "#             with torch.no_grad():\n",
    "#                 sample_images(val_dataloader,e,i)\n",
    "#                 print('[Epoch %d/%d]\\n[Batch %d/%d]\\n[D loss : %f]\\n[G loss : %f - (adv : %f, cycle : %f]'\n",
    "#                         %(e+1,n_epochs,       \n",
    "#                           i+1,len(dataloader),   \n",
    "#                           loss_D.item(),       \n",
    "#                           loss_G.item(),       \n",
    "#                           loss_GAN.item(),    \n",
    "#                           loss_cycle.item(), \n",
    "#                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor      = torch.cuda.FloatTensor\n",
    "G_loss      = []\n",
    "D_loss      = []\n",
    "D_accs      = []\n",
    "Dft_loss    = []\n",
    "num_classes = 2\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        real_A = batch['img_tr'].type(Tensor)\n",
    "        real_B = batch['img_te'].type(Tensor)\n",
    "        real_lbl = batch['lbl_tr'].type(Tensor).long()\n",
    "        \n",
    "        oneh = torch.eye(num_classes).to(device)\n",
    "        \n",
    "        source_label = torch.ones(real_A.size()[0]).long().to(device)\n",
    "        target_label = torch.zeros(real_B.size()[0]).long().to(device)\n",
    "        \n",
    "        G_AB.train()\n",
    "        G_BA.train()\n",
    "        \n",
    "        \n",
    "          \n",
    "        #Generator Forward Pass\n",
    "        fake_b         = G_AB(real_A)             #used throughout\n",
    "        fake_a         = G_BA(real_B)             #used only for cycle loss and discriminator A\n",
    "        recov_a        = G_BA(fake_b)\n",
    "        recov_b        = G_AB(fake_a)\n",
    "# ---------------------------------------------------------------------------------\n",
    "        #Feature Discriminator Forward Pass\n",
    "        pred_source    = D_ft(C_B(fake_b.detach())) # D_ft(C_B(G_A(A)))\n",
    "        pred_target    = D_ft(C_B(real_B))          # D_ft(C_B(B))\n",
    "        \n",
    "        dft_acc_source = discriminator_acc(pred_source, True)\n",
    "        dft_acc_targ   = discriminator_acc(pred_target, False)\n",
    "        \n",
    "        acc_D_ft       = (dft_acc_source + dft_acc_targ)/2 #feature discriminator accuracy\n",
    "        \n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_GAN_AB, _ = ganloss(D_B(fake_b), True)                # tricking the 'fake-B' into 'real-B'\n",
    "        loss_GAN_BA, _ = ganloss(D_A(fake_a), True)                # tricking the 'fake-A' into 'real-A'\n",
    "        loss_GAN       = (loss_GAN_AB + loss_GAN_BA)/2\n",
    "        \n",
    "        # cycle loss                                \n",
    "        loss_cycle_A   = cycleloss(recov_a, real_A)               # Reduces the difference between the restored image and the real image\n",
    "        loss_cycle_B   = cycleloss(recov_b, real_B)\n",
    "        loss_cycle     = (loss_cycle_A + loss_cycle_B)/2\n",
    "        \n",
    "        loss_G         = loss_GAN + (10.0*loss_cycle) # multiply suggested weight(default cycle loss weight : 10, default identity loss weight : 5)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        G_loss.append(loss_G.item())\n",
    "        \n",
    "# ----------------------------\n",
    "# Train Feature Discriminator\n",
    "# ----------------------------\n",
    "        optimizer_D_ft.zero_grad()\n",
    "        D_ft.train()\n",
    "        \n",
    "        loss_real_dft, _ = ganloss(D_ft(C_B(real_B)), True)                 \n",
    "        loss_fake_dft, _ = ganloss(D_ft(C_B(fake_b.detach())), False)\n",
    "                \n",
    "        dft_loss = (loss_real_dft + loss_fake_dft)*0.5\n",
    "        dft_loss.backward()\n",
    "        optimizer_D_ft.step()\n",
    "        Dft_loss.append(dft_loss.item())\n",
    "        \n",
    "# -----------------------------------------\n",
    "# Train Discriminator A and Discriminator B\n",
    "# -----------------------------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        loss_real_a, _ = ganloss(D_A(real_A), True)                # train to discriminate real images as real\n",
    "        loss_fake_a, _ = ganloss(D_A(fake_a.detach()), False)      # train to discriminate fake images as fake\n",
    "        \n",
    "        loss_D_A       = (loss_real_a + loss_fake_a)/2\n",
    "    \n",
    "        loss_real_b, _ = ganloss(D_B(real_B), True)                 # train to discriminate real images as real\n",
    "        loss_fake_b, _ = ganloss(D_B(fake_b.detach()), False)       # train to discriminate fake images as fake\n",
    "        \n",
    "        loss_D_B       = (loss_real_b + loss_fake_b)/2\n",
    "        \n",
    "        loss_D_A.backward()\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        loss_D         = (loss_D_A + loss_D_B)/2\n",
    "    \n",
    "        D_loss.append(loss_D.item())\n",
    "        \n",
    "# -----------------\n",
    "# Train Classifier A  #remember you only call this on training domain bc we only have labels for that domain.\n",
    "# -----------------\n",
    "        optimizer_C_A.zero_grad()\n",
    "        real_c        = C_A(real_A)\n",
    "        fake_c        = C_A(fake_b.detach())\n",
    "        sem_loss_a    = clsloss(real_c, oneh[real_lbl])                    #cross entropy loss\n",
    "        sem_loss_aa   = clsloss(fake_c, oneh[real_lbl])\n",
    "        sem_loss      = (sem_loss_a + sem_loss_aa)/2\n",
    "        \n",
    "        sem_loss.backward()\n",
    "        optimizer_C_A.step()\n",
    "        \n",
    "# -------------------\n",
    "# Train Classifier B\n",
    "# -------------------\n",
    "\n",
    "        optimizer_C_B.zero_grad()\n",
    "        cb_fake       = C_B(fake_b.detach()) \n",
    "        cb_loss       = clsloss(cb_fake, oneh[real_lbl]) #purple part in paper?\n",
    "\n",
    "        if acc_D_ft   > 0.6:\n",
    "            cb_real   = D_ft(C_B(real_B))\n",
    "            tgt_lbl   = torch.ones(real_B.size()[0]).long().to(device)\n",
    "            losscbadv = clsloss(cb_real, tgt_lbl)\n",
    "        else:\n",
    "            losscbadv = 0\n",
    "        loss_C_B      = cb_loss + losscbadv\n",
    "        \n",
    "        loss_C_B.backward()\n",
    "        optimizer_C_B.step()\n",
    "\n",
    "\n",
    "        \n",
    "# ---------------------------------Visualization---------------------------------       \n",
    "        if (i+1) % 200 == 0:\n",
    "            with torch.no_grad():\n",
    "                sample_images(val_dataloader,e,i)\n",
    "                print('[Epoch %d/%d]\\n[Batch %d/%d]\\n[D loss : %f]\\n[G loss : %f - (adv : %f, cycle : %f]'\n",
    "                        %(e+1,n_epochs,       \n",
    "                          i+1,len(dataloader),   \n",
    "                          loss_D.item(),       \n",
    "                          loss_G.item(),       \n",
    "                          loss_GAN.item(),    \n",
    "                          loss_cycle.item(), \n",
    "                          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dis_loss(genloss, disloss, epochs, save = True, fig_name=''):\n",
    "    epoch = range(epochs)\n",
    "    fig, ax = plt.subplots(1,1, figsize = (6,6))   \n",
    "    ax.plot(epoch, genloss, color='b', linewidth=0.5, label='Generator')\n",
    "    ax.plot(epoch, disloss, color='r', linewidth=0.5, label='Discriminator')\n",
    "    ax.set_xlabel('Iters')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Generator and Discriminator Loss')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    if save==True:\n",
    "        fig.savefig(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR+'/'+fig_name+'.png', transparent=False, facecolor='white', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dis_loss(G_loss, D_loss, len(D_loss), save = False, fig_name='gdloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
